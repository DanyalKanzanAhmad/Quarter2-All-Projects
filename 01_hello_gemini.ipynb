{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3mPWhLYAsE76mqVJhIfe3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanyalKanzanAhmad/Quarter2-All-Projects/blob/main/01_hello_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "R41iCykHaCFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain-google-genai"
      ],
      "metadata": {
        "id": "tXXHC0yzLHsq",
        "outputId": "4c932d8f-44fe-4f56-c827-8edfdaf57f36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.28)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.10.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n"
      ],
      "metadata": {
        "id": "LQMrvdr8aryG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GoogleGenerativeAI(\n",
        "    api_key=\"AIzaSyChawzna0i51r9gKLYlGvbHKlU4-SkuCzk\",\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "KbgeEy5Ka_a7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"You are a helpful assistant. Answer the following question:\\n\\n{question}\"\n",
        ")"
      ],
      "metadata": {
        "id": "mtkfJsGrcBzB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
        "# Run the chain with a sample question\n",
        "question = \"What is LangChain?\"\n",
        "response = chain.run({\"question\": question})\n",
        "\n",
        "print(\"Answer:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He-aL8VicLq0",
        "outputId": "dc72a94f-ae21-4c2e-97f9-3f3b1d782b26"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: LangChain is a framework for developing applications powered by large language models (LLMs).  It simplifies the process of building LLM-powered applications by providing modular components and tools for:\n",
            "\n",
            "* **Connecting to LLMs:** LangChain easily integrates with various LLMs, including OpenAI, Hugging Face Hub models, and others.  This allows developers to switch between different models without significant code changes.\n",
            "\n",
            "* **Managing chains of LLMs:**  Instead of using a single LLM call, LangChain allows you to create chains or sequences of calls, each building upon the previous one. This enables complex workflows and more sophisticated applications.\n",
            "\n",
            "* **Memory:** LangChain offers mechanisms for LLMs to retain information across multiple interactions, improving context and consistency in conversations.\n",
            "\n",
            "* **Indexes:** LangChain helps you index and query your own data, allowing LLMs to access and process your specific information, rather than relying solely on their pre-trained knowledge.  This is crucial for building applications that leverage private or specialized datasets.\n",
            "\n",
            "* **Agents:**  LangChain facilitates the creation of agents that can autonomously interact with the environment (e.g., search the web, access databases) to gather information and complete tasks.  This allows for more powerful and flexible applications.\n",
            "\n",
            "In essence, LangChain acts as a Lego-like system for building with LLMs. It provides the building blocks and simplifies the connections, allowing developers to focus on the application logic rather than the low-level details of LLM interaction.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Define the Gemini model configuration\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    api_key=\"AIzaSyChawzna0i51r9gKLYlGvbHKlU4-SkuCzk\",  # Replace with your Gemini API key\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.9,  # Default temperature for balanced responses\n",
        "    max_output_tokens=500\n",
        ")\n",
        "\n",
        "# Add memory to support multi-turn conversations\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Define the primary prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"You are a helpful assistant. Answer the following question:\\n\\n{question}\"\n",
        ")\n",
        "\n",
        "# Experiment with an additional prompt template (step-by-step explanation)\n",
        "step_by_step_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Explain the following question in a step-by-step manner:\\n\\n{question}\"\n",
        ")\n",
        "\n",
        "# Create the primary chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template, memory=memory)\n",
        "\n",
        "# Create an experimental chain for step-by-step responses\n",
        "step_by_step_chain = LLMChain(llm=llm, prompt=step_by_step_prompt, memory=memory)\n",
        "\n",
        "# Integrate a mock tool (e.g., database query simulation)\n",
        "def query_database(query):\n",
        "    return f\"Mock database result for query: {query}\"\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Database Query\",\n",
        "        func=query_database,\n",
        "        description=\"Use this tool to query a mock database.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize an agent with the tool\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, memory=memory)\n",
        "\n",
        "# Define a sample question\n",
        "question = \"What is LangChain?\"\n",
        "\n",
        "# Run the primary chain\n",
        "response = chain.run({\"question\": question})\n",
        "print(\"\\nPrimary Chain Response:\")\n",
        "display(Markdown(response))\n",
        "\n",
        "# Run the step-by-step chain\n",
        "step_by_step_response = step_by_step_chain.run({\"question\": question})\n",
        "print(\"\\nStep-by-Step Chain Response:\")\n",
        "display(Markdown(step_by_step_response))\n",
        "\n",
        "# Test the tool integration\n",
        "tool_query = \"What are the benefits of LangChain?\"\n",
        "agent_response = agent.run(tool_query)\n",
        "print(\"\\nAgent Response with Tool Integration:\")\n",
        "display(Markdown(agent_response))\n"
      ],
      "metadata": {
        "id": "2hp900G0OHzg",
        "outputId": "1af19c69-d411-43d8-edd8-4643484fbeff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Primary Chain Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangChain is a framework designed to make it easier to build applications using large language models (LLMs). Think of it as a toolkit that provides a standardized way to connect LLMs to other data sources and tools, enabling you to create more complex and sophisticated AI-powered applications.\n\nHere's a breakdown of what LangChain does and why it's useful:\n\n**Key Concepts and Features:**\n\n* **Composability:** LangChain emphasizes the idea of building applications by connecting various components together. It provides pre-built modules and utilities that can be easily combined and customized.\n* **LLM Integration:** The core of LangChain is its seamless integration with various LLMs, including OpenAI's GPT models, Hugging Face models, and more. It provides abstractions to interact with these models in a consistent way.\n* **Data Connection:** LangChain allows you to connect LLMs to external data sources, such as databases, APIs, documents, and the internet. This enables the models to access and utilize relevant information for more informed and context-aware responses.\n* **Tool Use:** It facilitates the use of external tools by LLMs. This can include anything from search engines and calculators to other APIs and specialized software.\n* **Chains:** LangChain's namesake comes from the concept of \"chains,\" which are sequences of calls to LLMs or other components. You can build complex workflows by chaining together different actions, allowing you to create more sophisticated applications.\n* **Agents:** LangChain also supports the creation of \"agents,\" which are LLMs that can dynamically decide which tools to use based on the user's input. This opens the door to more interactive and autonomous applications.\n* **Standardization:** LangChain provides a standardized way of working with LLMs and their ecosystem, making it easier for developers to learn, build, and share applications.\n* **Open Source:** It's an open-source project, meaning it's freely available for anyone to use and contribute to. This fosters a collaborative environment and drives innovation.\n\n**Why is LangChain Useful?**\n\n* **Abstraction:** It simplifies the complex interactions with LLMs, making it easier to build applications without requiring deep expertise in natural language processing.\n* **Rapid Prototyping:** The modular and composable nature of LangChain allows for rapid prototyping and experimentation.\n* **Enhanced Functionality:** It enables the creation of applications that go beyond simple text"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step-by-Step Chain Response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down the question \"What is LangChain?\" step-by-step. We'll approach it like we're explaining it to someone who has never heard of it before:\n\n**Step 1: Start with the Basic Concept - Large Language Models (LLMs)**\n\n* **Imagine a really smart computer program:** This program has been trained on massive amounts of text data (like books, websites, code).\n* **It learns patterns in language:** It understands grammar, vocabulary, and even different styles of writing.\n* **It can generate human-like text:** This is what we call a Large Language Model (LLM). Examples include OpenAI's GPT models (like GPT-3 and GPT-4), Google's LaMDA, and others.\n* **LLMs are powerful but have limitations:** They are often used for things like writing text, translating languages, answering questions, and generating code. However, they can be tricky to use in real-world applications.\n\n**Step 2: Introduce the Problem - LLMs Need Structure and Tools**\n\n* **LLMs by themselves are like powerful engines:** They have a lot of potential, but they need to be connected to the right components to build a functioning vehicle.\n* **Real-world applications require more than just text generation:** You might want to:\n    * Connect to databases to get specific data.\n    * Perform specific actions based on the generated text.\n    * Combine the output of multiple LLMs.\n    * Remember previous interactions (state).\n    * Interact with other tools and APIs.\n* **It's complicated to manage all this manually:** Without a good framework, it's hard to build sophisticated applications on top of LLMs.\n\n**Step 3: Define LangChain as the Solution - A Framework for Building LLM Applications**\n\n* **LangChain is a framework (or library):** It provides the building blocks and tools needed to connect LLMs to the external world and build complex applications.\n* **Think of it as a \"kit\" for LLM developers:** It gives you pre-built components that are useful for working with LLMs, making it easier to create powerful and reliable applications.\n* **Key components that LangChain provides:**\n    * **Chains:** These are sequences of calls to LLMs and other components, allowing you to build complex workflows.\n    * **"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Agent Response with Tool Integration:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The benefits of LangChain are:\n- Provides a standard interface for chains of models\n- Offers a wide variety of integrations with other tools\n- Makes it easier to build complex applications\n- Supports a wide range of language models\n- Enables rapid prototyping of applications"
          },
          "metadata": {}
        }
      ]
    }
  ]
}